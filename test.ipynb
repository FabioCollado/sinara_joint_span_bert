{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.optim import Optimizer\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spert.models\n",
    "from spert.entities import Dataset\n",
    "#from spert.evaluator import Evaluator\n",
    "from spert.input_reader import JsonInputReader, BaseInputReader\n",
    "from spert.loss import SpERTLoss, Loss\n",
    "#from spert.sampling import Sampler\n",
    "#from trainer import BaseTrainer\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer# TF TOKENIZER\n",
    "from spert import sampling\n",
    "from transformers import BertTokenizer #PYTORCH TOKENIZER\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#SCRIPT_PATH = os.path.dirname(os.path.realpath(__file__))\n",
    "from transformers import AutoTokenizer #, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets in the input reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_path = \"../spert-data/datasets/types.json\"\n",
    "train_path = \"../spert-data/datasets/train.json\"\n",
    "valid_path = \"../spert-data/datasets/evaluate.json\"\n",
    "\n",
    "input_reader = JsonInputReader(types_path = types_path, \n",
    "                               tokenizer = tokenizer, \n",
    "                               encoding = 'utf-8', \n",
    "                               max_span_size = 10,\n",
    "                               neg_entity_count = 100,\n",
    "                               neg_rel_count = 100)\n",
    "input_reader.read(dataset_path = train_path, dataset_label = 'train')\n",
    "input_reader.read(dataset_path = valid_path, dataset_label = 'validation')\n",
    "train_dataset = input_reader.get_dataset('train')\n",
    "validation_dataset = input_reader.get_dataset('validation')\n",
    "print(\"Number of documents in train = \", train_dataset.document_count)\n",
    "print(\"Number of documents in validation = \", validation_dataset.document_count)\n",
    "train_dataset.switch_mode(Dataset.TRAIN_MODE)\n",
    "data_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True, num_workers=0, \n",
    "                         collate_fn=sampling.collate_fn_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding data used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for batch in data_loader:\n",
    "    print('--------------        ENTRADA DA RN            ------------------')\n",
    "    print('--------------          encodings          ------------------')\n",
    "    print('encodings = ', tokenizer.convert_ids_to_tokens(batch['encodings'][0]))\n",
    "    print('encodings = ', tokenizer.convert_ids_to_tokens(batch['encodings'][1]))\n",
    "    assert len(batch['encodings'][0]) == len(batch['encodings'][1])\n",
    "    print('O documento deste batch com texto maior possui', \n",
    "          len(batch['encodings'][1]), 'tokens.')\n",
    "    print('context_masks = ', batch['context_masks'])\n",
    "    assert len(batch['context_masks'][0]) == len(batch['context_masks'][1])\n",
    "    assert len(batch['context_masks'][0]) == len(batch['encodings'][0])\n",
    "    print('size = ', len(batch['context_masks'][1]))\n",
    "    print('--------------          entity          ------------------')\n",
    "    print('entity_masks = ', batch['entity_masks'])\n",
    "    print('entity_types = ', batch['entity_types'])\n",
    "    assert len(batch['entity_masks'][0]) == len(batch['entity_masks'][1])\n",
    "    print('size = ', len(batch['entity_masks'][1]))\n",
    "    print('entity_sizes = ', batch['entity_sizes'])\n",
    "    assert len(batch['entity_sizes'][0]) == len(batch['entity_sizes'][1])\n",
    "    assert len(batch['entity_sizes'][0]) == len(batch['entity_masks'][0])\n",
    "    assert len(batch['entity_sizes'][0]) == len(batch['entity_types'][0])\n",
    "    print('O documento com mais entidades neste batch possui ', \n",
    "          len(batch['entity_sizes'][1]), ' entidades. Cada entidade tem seu tamanho',\n",
    "          'definido no batch[entity_sizes] e sua localização no batch[entity_masks].',\n",
    "          'Há muitas entidades pq foram geradas randomicamente para os exemplos negativos.')\n",
    "    print('--------------          rels          ------------------')\n",
    "    print('rels = ', batch['rels'])\n",
    "    assert len(batch['rels'][0]) == len(batch['rels'][1])\n",
    "    print('size = ', len(batch['rels'][1]))\n",
    "    print('rel_types = ', batch['rel_types'])\n",
    "    print('rel_masks = ', batch['rel_masks'])\n",
    "    assert len(batch['rel_masks'][0]) == len(batch['rel_masks'][1]) #mesmo batch\n",
    "    assert len(batch['rel_masks'][0]) == len(batch['rels'][0]) # ambos são qtde de relações\n",
    "    assert len(batch['rel_masks'][0]) == len(batch['rel_types'][0]) # ambos são qtde de relações\n",
    "    assert len(batch['rel_masks'][0][0]) == len(batch['encodings'][0]) #ambos são tamanho de texto\n",
    "    print('Há', len(batch['rel_masks'][0]), 'relações. O rel_masks,',\n",
    "          'marca a posição entre duas entidades, mas sem as entidades. Isso pode',\n",
    "          'não ser bom para minha aplicação por haver pouca informação.')\n",
    "    break\n",
    "\n",
    "def test_rel_and_ents(batch, batch_n):\n",
    "    encoded_text = np.array(batch['encodings'][batch_n])\n",
    "    print(tokenizer.convert_ids_to_tokens(encoded_text))\n",
    "    print('Showing only relations and entities with TYPE different from 0:')\n",
    "    for entity_mask, entity_type in zip(batch['entity_masks'][batch_n], batch['entity_types'][batch_n]):\n",
    "        if entity_type.numpy() > 0:\n",
    "            mask = np.array(entity_mask, dtype = np.bool)\n",
    "            print('   entity type =', entity_type.numpy(),\n",
    "                  ' - entity =', tokenizer.convert_ids_to_tokens(list(encoded_text[mask])))\n",
    "    for rel_mask, rel_type in zip(batch['rel_masks'][batch_n], batch['rel_types'][batch_n]):\n",
    "        if rel_type.numpy() > 0:\n",
    "            mask = np.array(rel_mask, dtype = np.bool)\n",
    "            print('   rel type =', rel_type.numpy(),\n",
    "                  ' - rel =', tokenizer.convert_ids_to_tokens(list(encoded_text[mask])))\n",
    "test_rel_and_ents(batch, 0)\n",
    "test_rel_and_ents(batch, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = train_dataset.documents[10:20] \n",
    "\n",
    "for doc in docs:\n",
    "    print(\"\\n---------------------------------------\")\n",
    "    print(tokenizer.convert_ids_to_tokens(doc.encoding))\n",
    "    print(doc.encoding)\n",
    "    print('\\nRelations:')\n",
    "    for rel in doc.relations:\n",
    "        print(rel.head_entity, \"   -   \", rel.tail_entity)\n",
    "    print('\\nEntities:')\n",
    "    for entity in doc.entities:\n",
    "        print(entity.phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando o SpERT\n",
    "## Problemas:\n",
    "- (ARRUMADO) Problema: Estou usando a base em inglês (bert-base-cased) ainda e o Tokenizer é tão ruim que meu dataset ultrapassa o limite de 510 tokens. E ultrapassa muito. Preciso usar o \"neuralmind/bert-base-portuguese-cased\".\n",
    "- (ARRUMADO) É IMPORTANTE QUE O 'NONE' (tanto nas relations quanto nas entidades) NO ARQUIVO spert-data/datasets/types.json ESTEJA POR ÚLTIMO! Caso contrário dá o erro: IndexError: Target 13 is out of bounds.\n",
    "- RuntimeError: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3480791040 bytes. Ocorreu ao dar evaluate após treinar com duas epochs. Batch de evaluate estava em 1 e de treino em 2. Subi ambos pra 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config='Namespace(cache_path=None, config='configs/example_train.conf', cpu=False, debug=False, epochs=20, eval_batch_size=1, example_count=None, final_eval=True, freeze_transformer=False, init_eval=False, label='conll04_train', log_path='data/log/', lowercase=False, lr=5e-05, lr_warmup=0.1, max_grad_norm=1.0, max_pairs=1000, max_span_size=10, model_path='bert-base-cased', model_type='spert', neg_entity_count=100, neg_relation_count=100, no_overlapping=False, prop_drop=0.1, rel_filter_threshold=0.4, sampling_processes=4, save_optimizer=False, save_path='data/save/', seed=None, size_embedding=25, store_examples=True, store_predictions=True, tokenizer_path='bert-base-cased', train_batch_size=2, train_log_iter=100, train_path='../spert-data/datasets/train.json', types_path='../spert-data/datasets/types.json', valid_path='../spert-data/datasets/evaluate.json', weight_decay=0.01)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./spert.py train --config configs/example_train.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_args: Namespace(cache_path=None, config='configs/example_train.conf', cpu=True, debug=False, epochs=2, eval_batch_size=2, example_count=1, final_eval=True, freeze_transformer=False, init_eval=True, label='conll04_train', log_path='data/log/', lowercase=False, lr=5e-05, lr_warmup=0.1, max_grad_norm=1.0, max_pairs=1000, max_span_size=10, model_path='bert-base-cased', model_type='spert', neg_entity_count=100, neg_relation_count=100, no_overlapping=False, prop_drop=0.1, rel_filter_threshold=0.4, sampling_processes=0, save_optimizer=False, save_path='data/save/', seed=123, size_embedding=25, store_examples=True, store_predictions=True, tokenizer_path='neuralmind/bert-base-portuguese-cased', train_batch_size=2, train_log_iter=100, train_path='../spert-data/datasets/train.json', types_path='../spert-data/datasets/types.json', valid_path='../spert-data/datasets/evaluate.json', weight_decay=0.01)\n",
      "i =  0\n",
      "save_path: data/save/conll04_train\\2022-03-15_10_48_55.422105  - self._args.label: conll04_train  - run_key: 2022-03-15_10_48_55.422105\n",
      "data/log/conll04_train\\2022-03-15_10_48_55.422105  log_path - args  Namespace(cache_path=None, config='configs/example_train.conf', cpu=True, debug=False, epochs=2, eval_batch_size=2, example_count=1, final_eval=True, freeze_transformer=False, init_eval=True, label='conll04_train', log_path='data/log/', lowercase=False, lr=5e-05, lr_warmup=0.1, max_grad_norm=1.0, max_pairs=1000, max_span_size=10, model_path='bert-base-cased', model_type='spert', neg_entity_count=100, neg_relation_count=100, no_overlapping=False, prop_drop=0.1, rel_filter_threshold=0.4, sampling_processes=0, save_optimizer=False, save_path='data/save/', seed=123, size_embedding=25, store_examples=True, store_predictions=True, tokenizer_path='neuralmind/bert-base-portuguese-cased', train_batch_size=2, train_log_iter=100, train_path='../spert-data/datasets/train.json', types_path='../spert-data/datasets/types.json', valid_path='../spert-data/datasets/evaluate.json', weight_decay=0.01)\n",
      "------------------------\n",
      "------training----------\n",
      "------------------------\n",
      "2022-03-15 10:48:58,556 [MainThread  ] [INFO ]  Datasets: ../spert-data/datasets/train.json, ../spert-data/datasets/evaluate.json\n",
      "2022-03-15 10:48:58,558 [MainThread  ] [INFO ]  Model type: spert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parse dataset 'train': 100%|██████████| 4522/4522 [00:42<00:00, 105.35it/s]\n",
      "Parse dataset 'valid': 100%|██████████| 1131/1131 [00:10<00:00, 111.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 10:49:51,984 [MainThread  ] [INFO ]  Relation type count: 2\n",
      "2022-03-15 10:49:51,985 [MainThread  ] [INFO ]  Entity type count: 14\n",
      "2022-03-15 10:49:51,986 [MainThread  ] [INFO ]  Entities:\n",
      "2022-03-15 10:49:51,987 [MainThread  ] [INFO ]  None=14\n",
      "2022-03-15 10:49:51,988 [MainThread  ] [INFO ]  Artigo=1\n",
      "2022-03-15 10:49:51,988 [MainThread  ] [INFO ]  Parágrafo=2\n",
      "2022-03-15 10:49:51,989 [MainThread  ] [INFO ]  Inciso=3\n",
      "2022-03-15 10:49:51,989 [MainThread  ] [INFO ]  Alínea=4\n",
      "2022-03-15 10:49:51,990 [MainThread  ] [INFO ]  Diploma=5\n",
      "2022-03-15 10:49:51,991 [MainThread  ] [INFO ]  Tema do STJ=6\n",
      "2022-03-15 10:49:51,991 [MainThread  ] [INFO ]  Súmula do STJ=7\n",
      "2022-03-15 10:49:51,992 [MainThread  ] [INFO ]  Tema do STF=8\n",
      "2022-03-15 10:49:51,993 [MainThread  ] [INFO ]  Súmula do STF=9\n",
      "2022-03-15 10:49:51,993 [MainThread  ] [INFO ]  Súmula do TRF3=10\n",
      "2022-03-15 10:49:51,994 [MainThread  ] [INFO ]  Súmula Vinculante=11\n",
      "2022-03-15 10:49:51,995 [MainThread  ] [INFO ]  Item=12\n",
      "2022-03-15 10:49:51,996 [MainThread  ] [INFO ]  Precedente=13\n",
      "2022-03-15 10:49:51,996 [MainThread  ] [INFO ]  Relations:\n",
      "2022-03-15 10:49:51,997 [MainThread  ] [INFO ]  None=2\n",
      "2022-03-15 10:49:51,997 [MainThread  ] [INFO ]  P=1\n",
      "2022-03-15 10:49:51,998 [MainThread  ] [INFO ]  Dataset: train\n",
      "2022-03-15 10:49:51,998 [MainThread  ] [INFO ]  Document count: 4522\n",
      "2022-03-15 10:49:51,999 [MainThread  ] [INFO ]  Relation count: 9263\n",
      "2022-03-15 10:49:51,999 [MainThread  ] [INFO ]  Entity count: 25402\n",
      "2022-03-15 10:49:52,000 [MainThread  ] [INFO ]  Dataset: valid\n",
      "2022-03-15 10:49:52,001 [MainThread  ] [INFO ]  Document count: 1131\n",
      "2022-03-15 10:49:52,001 [MainThread  ] [INFO ]  Relation count: 2965\n",
      "2022-03-15 10:49:52,002 [MainThread  ] [INFO ]  Entity count: 5451\n",
      "2022-03-15 10:49:52,003 [MainThread  ] [INFO ]  Updates per epoch: 2261\n",
      "2022-03-15 10:49:52,003 [MainThread  ] [INFO ]  Updates total: 4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 10:49:54,607 [MainThread  ] [INFO ]  Evaluate: valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\.conda\\envs\\spert\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Evaluate epoch 0:   0%|          | 0/566 [00:00<?, ?it/s]C:\\Users\\fabio\\.conda\\envs\\spert\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Evaluate epoch 0: 100%|██████████| 566/566 [27:14<00:00,  2.89s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "\n",
      "--- Entities (named entity recognition (NER)) ---\n",
      "An entity is considered correct if the entity type and span is predicted correctly\n",
      "\n",
      "                type    precision       recall     f1-score      support\n",
      "              Artigo        89.74        99.00        94.15         1803\n",
      "              Inciso        91.53        99.56        95.38          684\n",
      "      Súmula do TRF3         0.00         0.00         0.00            1\n",
      "          Precedente        40.00        72.10        51.45          319\n",
      "           Parágrafo        80.25        97.01        87.84          603\n",
      "         Tema do STF        25.00        87.50        38.89            8\n",
      "         Tema do STJ         0.00         0.00         0.00            9\n",
      "       Súmula do STF        58.33        60.87        59.57           23\n",
      "              Alínea        68.91        90.11        78.10           91\n",
      "   Súmula Vinculante         0.00         0.00         0.00            1\n",
      "       Súmula do STJ        62.65        85.25        72.22           61\n",
      "             Diploma        64.29        93.18        76.09         1832\n",
      "                Item         0.00         0.00         0.00           16\n",
      "\n",
      "               micro        73.96        94.35        82.92         5451\n",
      "               macro        44.67        60.35        50.28         5451\n",
      "\n",
      "--- Relations ---\n",
      "\n",
      "Without named entity classification (NEC)\n",
      "A relation is considered correct if the relation type and the spans of the two related entities are predicted correctly (entity type is not considered)\n",
      "\n",
      "                type    precision       recall     f1-score      support\n",
      "                   P        67.88        88.50        76.83         2964\n",
      "\n",
      "               micro        67.88        88.50        76.83         2964\n",
      "               macro        67.88        88.50        76.83         2964\n",
      "\n",
      "With named entity classification (NEC)\n",
      "A relation is considered correct if the relation type and the two related entities are predicted correctly (in span and entity type)\n",
      "\n",
      "                type    precision       recall     f1-score      support\n",
      "                   P        67.08        87.45        75.92         2964\n",
      "\n",
      "               micro        67.08        87.45        75.92         2964\n",
      "               macro        67.08        87.45        75.92         2964\n",
      "2022-03-15 11:17:31,465 [MainThread  ] [INFO ]  Train epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0:  10%|█         | 229/2261 [10:14<1:30:50,  2.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_71960/3152984590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"# REQUIRES NOTHING ABOVE. RUN SOLO.\\nimport argparse\\nfrom spert import input_reader\\nfrom spert.spert_trainer import SpERTTrainer\\nimport configparser\\n\\ndef eval_dict(config):\\n    for key, value in config.items():\\n        if key != 'model_type':\\n            try:\\n                config[key] = eval(value)\\n            except:\\n                pass\\n    return config\\n#from config_reader import _read_config\\n#config = _read_config('configs/example_train.conf')[0][1]\\nconfig = configparser.ConfigParser()\\nconfig.read('configs/example_train.conf')\\nconfig = dict(config['1'].items())\\nconfig = eval_dict(config)\\nrun_args = argparse.Namespace(**config)\\nprint('run_args:', run_args)\\nfor i in range (4):\\n    print('i = ', i)\\n    trainer = SpERTTrainer(run_args)\\n    print('------------------------')\\n    print('------training----------')\\n    print('------------------------')\\n    trainer.train(train_path=run_args.train_path, valid_path=run_args.valid_path,\\n                  types_path=run_args.types_path, input_reader_cls=input_reader.JsonInputReader)\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2406\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2407\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2_TRF3\\Projetos\\1_SINARA\\SINARA\\spert-SINARA-pytorch\\spert\\spert_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_path, valid_path, types_path, input_reader_cls)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# train epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;31m# eval validation sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_eval\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2_TRF3\\Projetos\\1_SINARA\\SINARA\\spert-SINARA-pytorch\\spert\\spert_trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, model, compute_loss, optimizer, dataset, updates_epoch, epoch)\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             entity_logits, rel_logits = model(encodings=batch['encodings'], \n\u001b[0m\u001b[0;32m    195\u001b[0m                                               \u001b[0mcontext_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'context_masks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                                               \u001b[0mentity_masks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entity_masks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\spert\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2_TRF3\\Projetos\\1_SINARA\\SINARA\\spert-SINARA-pytorch\\spert\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inference, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2_TRF3\\Projetos\\1_SINARA\\SINARA\\spert-SINARA-pytorch\\spert\\models.py\u001b[0m in \u001b[0;36m_forward_train\u001b[1;34m(self, encodings, context_masks, entity_masks, entity_sizes, relations, rel_masks)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# classify entities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0msize_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_sizes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# embed entity candidate sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mentity_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_spans_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_classify_entities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# classify relations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2_TRF3\\Projetos\\1_SINARA\\SINARA\\spert-SINARA-pytorch\\spert\\models.py\u001b[0m in \u001b[0;36m_classify_entities\u001b[1;34m(self, encodings, h, entity_masks, size_embeddings)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mentity_masks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1e30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mentity_spans_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_masks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mentity_spans_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_spans_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# get cls token as candidate context representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# REQUIRES NOTHING ABOVE. RUN SOLO.\n",
    "import argparse\n",
    "from spert import input_reader\n",
    "from spert.spert_trainer import SpERTTrainer\n",
    "import configparser\n",
    "\n",
    "def eval_dict(config):\n",
    "    for key, value in config.items():\n",
    "        if key != 'model_type':\n",
    "            try:\n",
    "                config[key] = eval(value)\n",
    "            except:\n",
    "                pass\n",
    "    return config\n",
    "#from config_reader import _read_config\n",
    "#config = _read_config('configs/example_train.conf')[0][1]\n",
    "config = configparser.ConfigParser()\n",
    "config.read('configs/example_train.conf')\n",
    "config = dict(config['1'].items())\n",
    "config = eval_dict(config)\n",
    "run_args = argparse.Namespace(**config)\n",
    "print('run_args:', run_args)\n",
    "for i in range (4):\n",
    "    print('i = ', i)\n",
    "    trainer = SpERTTrainer(run_args)\n",
    "    print('------------------------')\n",
    "    print('------training----------')\n",
    "    print('------------------------')\n",
    "    trainer.train(train_path=run_args.train_path, valid_path=run_args.valid_path,\n",
    "                  types_path=run_args.types_path, input_reader_cls=input_reader.JsonInputReader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_reader\n",
    "\n",
    "input_reader.read({'train': train_path, 'validation': valid_path})\n",
    "\n",
    ".context_size = 512\n",
    "\n",
    ".vocabulary_size = 29794\n",
    "\n",
    ".datasets = {'train': <entities.Dataset>, 'validation': <entities.Dataset>}\n",
    "\n",
    "    train_dataset = input_reader.get_dataset('train')\n",
    "    \n",
    ".entity_types = OrderedDict([('None', <entities.EntityType>), ('Artigo', <entities.EntityType>)...)])\n",
    "\n",
    "    .entity_type_count = 13\n",
    "    entity_type_none = input_reader.get_entity_type(0)\n",
    "\n",
    ".relation_types = OrderedDict([('P', <entities.RelationType>), ('None', <entities.RelationType>)])\n",
    "    \n",
    "    .relation_type_count = 2\n",
    "    relation_type_none = input_reader.get_relation_type(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset\n",
    "\n",
    "(train_dataset)\n",
    "\n",
    ".label = train\n",
    "\n",
    ".documents = [<entities.Document>, <entities.Document>, ...]\n",
    "\n",
    ".document_count = 707\n",
    "\n",
    ".entities = [<entities.Entity>, <entities.Entity>, ...]\n",
    "\n",
    "    .entity_count = 3686\n",
    "\n",
    ".relations = [<entities.Relation>, <entities.Relation>, ...]\n",
    "\n",
    "    .relation_count = 2151\n",
    "\n",
    "\n",
    ".input_reader = \n",
    "\n",
    ".iterate_documents\n",
    "\n",
    ".iterate_relations\n",
    "\n",
    ".create_document\n",
    "\n",
    ".create_entity\n",
    "\n",
    ".create_relation\n",
    "\n",
    ".create_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### document\n",
    "\n",
    ".doc_id = 1\n",
    "\n",
    ".encoding = [101, 298, 8746, 14643, 442, ...]\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(train_dataset.documents[1].encoding) = ['[CLS]', 'dos', 'dispositivos', ...]\n",
    "\n",
    ".entities = [<entities.Entity>, <entities.Entity>, ...]\n",
    "\n",
    ".relations = [<entities.Relation>, <entities.Relation>, ...]\n",
    "\n",
    ".tokens = <entities.TokenSpan object at 0x7f2eab851710>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TokenSpan\n",
    "\n",
    "len(train_dataset.documents[1].encoding) = 156\n",
    "\n",
    ".span = (1, 155)\n",
    "\n",
    ".span_start = 1\n",
    "\n",
    ".span_end = 155\n",
    "\n",
    "len() = number of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity\n",
    "\n",
    ".as_tuple\n",
    "\n",
    ".entity_type = <entities.EntityType object at 0x7f2ed3d606d0>\n",
    "\n",
    ".phrase = 202\n",
    "\n",
    ".span = (54, 55)\n",
    "\n",
    "    .span_start = 54\n",
    "    .span_end = 55\n",
    "    .tokens = <entities.TokenSpan>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relation\n",
    "\n",
    ".as_tuple\n",
    "\n",
    ".first_entity = decreto - lei [UNK] 28 ##8 / 67\n",
    "\n",
    ".second_entity = ##o\n",
    "\n",
    ".reverse = True\n",
    "\n",
    ".head_entity (quando .reverse = True, .first_entity = .head_entity\n",
    "\n",
    ".tail_entity = decreto - lei [UNK] 28 ##8 / 67\n",
    "\n",
    ".relation_type = <entities.RelationType>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4\n",
    "eval_batch_size = 1\n",
    "neg_entity_count = 100\n",
    "neg_relation_count = 100\n",
    "lr = 5e-5\n",
    "lr_warmup = 0.1\n",
    "weight_decay = 0.01\n",
    "\n",
    "rel_filter_threshold = 0.4\n",
    "size_embedding = 25\n",
    "prop_drop = 0.1\n",
    "max_span_size = 10\n",
    "store_examples = True\n",
    "sampling_processes = 4\n",
    "sampling_limit = 100\n",
    "max_pairs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "size_embedding = 100\n",
    "freeze_transformer = True\n",
    "\n",
    "context_size = input_reader.context_size\n",
    "rel_type_count = input_reader.relation_type_count\n",
    "\n",
    "train_sample_count = train_dataset.document_count\n",
    "print('train_sample_count=',train_sample_count)\n",
    "updates_epoch = train_sample_count // train_batch_size\n",
    "updates_total = updates_epoch * epochs\n",
    "\n",
    "#use model_path to start fresh\n",
    "#use _save_path to continue the training\n",
    "model_path='bert-base-portuguese-cased'\n",
    "_save_path = \"data/saved_model/final_model\"\n",
    "checkpoint_path = _save_path\n",
    "\n",
    "def create_train_sampler():\n",
    "    sampler = Sampler(0,0)\n",
    "    sampler = sampler.create_train_sampler(dataset=train_dataset, batch_size=train_batch_size, max_span_size=max_span_size,\n",
    "                                                     context_size=context_size, neg_entity_count=neg_entity_count,\n",
    "                                                     neg_rel_count=neg_relation_count, truncate=True)\n",
    "    return sampler\n",
    "sampler = create_train_sampler()\n",
    "\n",
    "model_class = models.get_model('SpERT')\n",
    "\n",
    "# from_pretrained is a method from the superclass BertPreTrainedModel that loads BERT's weights\n",
    "\n",
    "model = model_class.from_pretrained(checkpoint_path,\n",
    "                                            cache_dir=\"\",\n",
    "                                            # SpERT model parameters\n",
    "                                            cls_token=tokenizer.convert_tokens_to_ids(['[CLS]'])[0],\n",
    "                                            # no node for 'none' class\n",
    "                                            relation_types=input_reader.relation_type_count - 1,\n",
    "                                            entity_types=input_reader.entity_type_count,\n",
    "                                            max_pairs=max_pairs,\n",
    "                                            prop_drop=0.1,\n",
    "                                            size_embedding=size_embedding,\n",
    "                                            freeze_transformer=freeze_transformer)\n",
    "model.zero_grad()\n",
    "\n",
    "iteration = 0\n",
    "total = train_dataset.document_count // train_batch_size\n",
    "def _get_optimizer_params(model):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_params = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    return optimizer_params\n",
    "\n",
    "rel_criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "entity_criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer_params = _get_optimizer_params(model)\n",
    "optimizer = AdamW(optimizer_params, lr=lr, weight_decay=weight_decay, correct_bias=False)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                                         num_warmup_steps=lr_warmup * updates_total,\n",
    "                                                         num_training_steps=updates_total)\n",
    "\n",
    "from transformers import PreTrainedModel\n",
    "import util\n",
    "def _save_model(save_path: str, model: PreTrainedModel, iteration: int, optimizer: Optimizer = None,\n",
    "                    save_as_best: bool = False, extra: dict = None, include_iteration: int = True, name: str = 'model'):\n",
    "    extra_state = dict(iteration=iteration)\n",
    "\n",
    "    if optimizer:\n",
    "        extra_state['optimizer'] = optimizer.state_dict()\n",
    "\n",
    "    if extra:\n",
    "        extra_state.update(extra)\n",
    "\n",
    "    if save_as_best:\n",
    "        dir_path = os.path.join(save_path, '%s_best' % name)\n",
    "    else:\n",
    "        dir_name = '%s_%s' % (name, iteration) if include_iteration else name\n",
    "        dir_path = os.path.join(save_path, dir_name)\n",
    "\n",
    "    util.create_directories_dir(dir_path)\n",
    "\n",
    "    if isinstance(model, DataParallel):\n",
    "        model.module.save_pretrained(dir_path)\n",
    "    else:\n",
    "        model.save_pretrained(dir_path)\n",
    "    state_path = os.path.join(dir_path, 'extra.state')\n",
    "    torch.save(extra_state, state_path)\n",
    "    print(\"model saved\")\n",
    "\n",
    "# save final model\n",
    "save_optimizer = True\n",
    "extra = dict(epoch=epochs, updates_epoch=updates_epoch, epoch_iteration=0)\n",
    "global_iteration = epochs * updates_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n in sampler:\n",
    "    #print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLER\n",
    "iterator of <sampling.TrainTensorBatch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrainTensorBatch\n",
    "\n",
    ".ctx_masks = tensor shape (batch, context_size)\n",
    "\n",
    ".encodings = tensor shape (batch, context_size)\n",
    "\n",
    "\n",
    "\n",
    ".entity_types = tensor shape (batch, num_of_entities) of integers\n",
    "\n",
    ".entity_masks = tensor shape (batch, num_of_entities, 512) of 0 or 1, with num_of_entities = max number of entities in the batch\n",
    "\n",
    ".entity_sizes = tensor shape (batch, num_of_entities) of integers\n",
    "\n",
    ".entity_sample_masks = vector, True if exists an entity in that position, False elsewhere. Needed because in the batch each example has a different number of entities. So, when a stacked them in a matrix I padded them. The padded ones are False, the real ones are True. shape (6, num_of_entities)\n",
    "\n",
    "\n",
    "\n",
    ".rels = tensor shape (batch, num_of_relations, 2), with num_of_relations = max number of relations in the batch\n",
    "\n",
    "    .rel_types\n",
    "\n",
    "    .rel_masks = tensor shape (batch, num_of_relations, 512)\n",
    "\n",
    "    .rel_sample_masks = vector, all True. shape (6, num_of_relations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "compute_loss = SpERTLoss(rel_criterion, entity_criterion, model, optimizer, scheduler, max_grad_norm)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    sampler = create_train_sampler()\n",
    "    for batch in tqdm(sampler, total=total):\n",
    "        model.train()\n",
    "\n",
    "        # relation types to one-hot encoding\n",
    "        rel_types_onehot = torch.zeros([batch.rel_types.shape[0], batch.rel_types.shape[1],\n",
    "                                        rel_type_count], dtype=torch.float32)\n",
    "        rel_types_onehot.scatter_(2, batch.rel_types.unsqueeze(2), 1)\n",
    "        rel_types_onehot = rel_types_onehot[:, :, 1:]  # all zeros for 'none' relation\n",
    "\n",
    "        # forward step\n",
    "        entity_logits, rel_logits = model(batch.encodings, batch.ctx_masks, batch.entity_masks,\n",
    "                                          batch.entity_sizes, batch.rels, batch.rel_masks)\n",
    "\n",
    "        # compute loss and optimize parameters\n",
    "        batch_loss = compute_loss.compute(rel_logits, rel_types_onehot, entity_logits,\n",
    "                                          batch.entity_types, batch.rel_sample_masks, batch.entity_sample_masks)\n",
    "\n",
    "        # logging\n",
    "        iteration += 1\n",
    "        print(batch_loss)\n",
    "\n",
    "    _save_model(_save_path, model = model, iteration = global_iteration,\n",
    "                             optimizer=optimizer if save_optimizer else None, extra=extra,\n",
    "                             include_iteration=False, name='final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from evaluator import Evaluator\n",
    "example_count=1\n",
    "epoch=1\n",
    "\n",
    "evaluator = Evaluator(validation_dataset, input_reader, tokenizer,\n",
    "                              rel_filter_threshold, example_count,\n",
    "                              valid_path, epoch, validation_dataset.label)\n",
    "\n",
    "        # create batch sampler\n",
    "eval_sampler = Sampler(0,0)\n",
    "eval_sampler = eval_sampler.create_eval_sampler(validation_dataset, eval_batch_size, max_span_size,\n",
    "                                            input_reader.context_size, truncate=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # iterate batches\n",
    "    total = math.ceil(validation_dataset.document_count / eval_batch_size)\n",
    "    for batch in tqdm(eval_sampler, total=total, desc='Evaluate epoch %s' % epoch):\n",
    "        # move batch to selected device\n",
    "        # run model (forward pass)\n",
    "        entity_clf, rel_clf, rels = model(batch.encodings, batch.ctx_masks, batch.entity_masks,\n",
    "                                          batch.entity_sizes, batch.entity_spans, batch.entity_sample_masks,\n",
    "                                          evaluate=True)\n",
    "\n",
    "        # evaluate batch\n",
    "        evaluator.eval_batch(entity_clf, rel_clf, rels, batch)\n",
    "\n",
    "global_iteration = epoch * updates_epoch + iteration\n",
    "ner_eval, rel_eval, rel_nec_eval = evaluator.compute_scores()\n",
    "#self._log_eval(*ner_eval, *rel_eval, *rel_nec_eval,\n",
    "               #epoch, iteration, global_iteration, validation_dataset.label)\n",
    "evaluator.store_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ctx = torch.zeros([0, 2048, 768])\n",
    "entity_spans_pool = torch.zeros([4, 818, 768])\n",
    "size_embeddings = torch.zeros([4, 818, 100])\n",
    "print(entity_ctx.unsqueeze(1).shape)\n",
    "print(entity_spans_pool.shape[1])\n",
    "entity_repr = entity_ctx.unsqueeze(1).repeat(1, entity_spans_pool.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2,2])\n",
    "b = a.repeat(2,2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # train epoch\n",
    "    self._train_epoch(model, compute_loss, optimizer, train_dataset, updates_epoch, epoch,\n",
    "                      input_reader.context_size, input_reader.relation_type_count)\n",
    "    # context_size é o tamanho do maior parágrafo considerando:\n",
    "    # byte-pair document encoding including special tokens ([CLS] and [SEP])\n",
    "\n",
    "    # eval validation sets\n",
    "    if not args.final_eval or (epoch == args.epochs - 1):\n",
    "        self._eval(model, validation_dataset, input_reader, epoch + 1, updates_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtokens=['controle', 'de', 'constitucional', '##idade', 'de', 'normas', ':', 'reserva', 'de', 'plena', '##rio', 'constitui', '##ca', '##o', 'federal', 'art', '97', ':', 'repu', '##ta', '-', 'se', 'declara', '##tor', '##io', 'de', 'incons', '##titu', '##cional', '##idade', 'o', 'acorda', '##o', 'que', '-', 'embora', 'sem', 'o', 'explic', '##itar', '-', 'afas', '##ta', 'a', 'inc', '##iden', '##cia', 'da', 'norma', 'ord', '##inar', '##ia', 'per', '##tin', '##ente', 'a', 'li', '##de', 'para', 'decid', '##i', '-', 'la', 'sob', 'crit', '##eri', '##os', 'diversos', 'alega', '##damente', 'extra', '##idos', 'da', 'constitui', '##ca', '##o']\n",
    "\n",
    "for i, token_phrase in enumerate(jtokens):\n",
    "    token_encoding = tokenizer.convert_tokens_to_ids(token_phrase)\n",
    "    print(token_encoding, ' - ', token_phrase)\n",
    "    #span_start, span_end = (len(doc_encoding), len(doc_encoding) + len(token_encoding))\n",
    "\n",
    "    # Cria um token, adiciona no dataset e o retorna pra ca\n",
    "    #token = dataset.create_token(i, span_start, span_end, token_phrase)\n",
    "\n",
    "    #doc_tokens.append(token)\n",
    "    #doc_encoding += token_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids('q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragrafo ='Implicitamente, considera-se que o art. 60 da Constituição é inalterável, pois alterações neste artigo permitiriam uma revisão completa da Constituição. Nos casos não abordados pelo art. 60, é possível propor emendas. Os órgãos competentes para submeter emendas são: a Câmara dos Deputados, o Senado Federal, o Presidente da República e de mais da metade das Assembleias Legislativas das unidades da Federação, manifestando-se, cada uma delas, pela maioria relativa de seus membros. '\n",
    "\n",
    "a=tokenizer.tokenize(paragrafo)\n",
    "for b in a:\n",
    "    c=tokenizer.convert_tokens_to_ids(b)\n",
    "    print(c)\n",
    "print(len(a), ' - ', len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_reader.context_size)\n",
    "print(input_reader.vocabulary_size)\n",
    "print(input_reader.entity_type_count)\n",
    "print(input_reader.relation_types)\n",
    "print(input_reader.datasets)\n",
    "for rel_type in input_reader.relation_types:\n",
    "    print(rel_type)\n",
    "dataset = input_reader.datasets['train']\n",
    "docs = dataset._documents\n",
    "print(docs[0]._entities[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "\n",
    "text_1 = \"Who was Jim Henson ?\"\n",
    "text_2 = \"Jim Henson was a puppeteer\"\n",
    "\n",
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpERTTrainer(BaseTrainer):\n",
    "    \"\"\" Joint entity and relation extraction training and evaluation \"\"\"\n",
    "\n",
    "    def __init__(self, args: argparse.Namespace):\n",
    "        super().__init__(args)\n",
    "\n",
    "        model_dir = os.path.abspath(os.getcwd())+\"/../../../../LIAA-3R/SINARA/bert-base-pt-cased-tensorflow\"\n",
    "        self._tf_bert_tokenizer = FullTokenizer(vocab_file=os.path.join(model_dir, \"vocab.txt\"))\n",
    "\n",
    "        # byte-pair encoding\n",
    "        self._tokenizer = BertTokenizer.from_pretrained(args.tokenizer_path,\n",
    "                                                        do_lower_case=args.lowercase,\n",
    "                                                        cache_dir=args.cache_path)\n",
    "\n",
    "        # path to export relation extraction examples to\n",
    "        self._examples_path = os.path.join(self._log_path, 'examples_%s_%s_epoch_%s.html')\n",
    "\n",
    "        # sampler (create and batch training/evaluation samples)\n",
    "        self._sampler = Sampler(processes=args.sampling_processes, limit=args.sampling_limit)\n",
    "\n",
    "    def train(self, train_path: str, valid_path: str, types_path: str):\n",
    "        \n",
    "        args = self.args\n",
    "\n",
    "        self._logger.info(\"Datasets: %s, %s\" % (train_path, valid_path))\n",
    "        self._logger.info(\"Model type: %s\" % args.model_type)\n",
    "\n",
    "        # create log csv files\n",
    "        self._init_train_logging('train')\n",
    "        self._init_eval_logging('validation')\n",
    "\n",
    "        # read datasets\n",
    "        input_reader = JsonInputReader(types_path, self._tokenizer, self._logger)\n",
    "        input_reader.read({'train': train_path, 'validation': valid_path})\n",
    "        self._log_datasets(input_reader)\n",
    "\n",
    "        train_dataset = input_reader.get_dataset('train')\n",
    "        \n",
    "        \n",
    "        train_sample_count = train_dataset.document_count\n",
    "        updates_epoch = train_sample_count // args.train_batch_size\n",
    "        updates_total = updates_epoch * args.epochs\n",
    "\n",
    "        validation_dataset = input_reader.get_dataset('validation')\n",
    "\n",
    "        self._logger.info(\"Updates per epoch: %s\" % updates_epoch)\n",
    "        self._logger.info(\"Updates total: %s\" % updates_total)\n",
    "\n",
    "        # create model\n",
    "        model_class = models.get_model(self.args.model_type)\n",
    "\n",
    "        # load model\n",
    "        model = model_class.from_pretrained(self.args.model_path,\n",
    "                                            cache_dir=self.args.cache_path,\n",
    "                                            # SpERT model parameters\n",
    "                                            cls_token=self._tokenizer.convert_tokens_to_ids('[CLS]'),\n",
    "                                            # no node for 'none' class\n",
    "                                            relation_types=input_reader.relation_type_count - 1,\n",
    "                                            entity_types=input_reader.entity_type_count,\n",
    "                                            max_pairs=self.args.max_pairs,\n",
    "                                            prop_drop=self.args.prop_drop,\n",
    "                                            size_embedding=self.args.size_embedding,\n",
    "                                            freeze_transformer=self.args.freeze_transformer)\n",
    "\n",
    "        # create loss function\n",
    "        rel_criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "        entity_criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        compute_loss = SpERTLoss(rel_criterion, entity_criterion, model, optimizer, scheduler, max_grad_norm)\n",
    "\n",
    "        # eval validation set\n",
    "        if args.init_eval:\n",
    "            self._eval(model, validation_dataset, input_reader, 0, updates_epoch)\n",
    "\n",
    "        # train\n",
    "        for epoch in range(args.epochs):\n",
    "            # train epoch\n",
    "            self._train_epoch(model, compute_loss, optimizer, train_dataset, updates_epoch, epoch,\n",
    "                              input_reader.context_size, input_reader.relation_type_count)\n",
    "            # context_size é o tamanho do maior parágrafo considerando:\n",
    "            # byte-pair document encoding including special tokens ([CLS] and [SEP])\n",
    "\n",
    "            # eval validation sets\n",
    "            if not args.final_eval or (epoch == args.epochs - 1):\n",
    "                self._eval(model, validation_dataset, input_reader, epoch + 1, updates_epoch)\n",
    "\n",
    "        # save final model\n",
    "        extra = dict(epoch=args.epochs, updates_epoch=updates_epoch, epoch_iteration=0)\n",
    "        global_iteration = args.epochs * updates_epoch\n",
    "        self._save_model(self._save_path, model, global_iteration,\n",
    "                         optimizer=optimizer if self.args.save_optimizer else None, extra=extra,\n",
    "                         include_iteration=False, name='final_model')\n",
    "\n",
    "        self._logger.info(\"Logged in: %s\" % self._log_path)\n",
    "        self._logger.info(\"Saved in: %s\" % self._save_path)\n",
    "\n",
    "        self._sampler.join()\n",
    "\n",
    "    def eval(self, dataset_path: str, types_path: str):\n",
    "        # read datasets\n",
    "        input_reader = JsonInputReader(types_path, self._tokenizer, self._logger)\n",
    "        input_reader.read({'evaluate': dataset_path})\n",
    "  \n",
    "        # create model\n",
    "        model_class = models.get_model(self.args.model_type)\n",
    "\n",
    "        # load model\n",
    "        model = model_class.from_pretrained(self.args.model_path,\n",
    "                                            cache_dir=self.args.cache_path,\n",
    "                                            # additional model parameters\n",
    "                                            cls_token=self._tokenizer.convert_tokens_to_ids('[CLS]'),\n",
    "                                            # no node for 'none' class\n",
    "                                            relation_types=input_reader.relation_type_count - 1,\n",
    "                                            entity_types=input_reader.entity_type_count,\n",
    "                                            max_pairs=self.args.max_pairs,\n",
    "                                            prop_drop=self.args.prop_drop,\n",
    "                                            size_embedding=self.args.size_embedding,\n",
    "                                            freeze_transformer=self.args.freeze_transformer)\n",
    "\n",
    "        # evaluate\n",
    "        self._eval(model, input_reader.get_dataset('evaluate'), input_reader)\n",
    "        self._logger.info(\"Logged in: %s\" % self._log_path)\n",
    "\n",
    "        self._sampler.join()\n",
    "\n",
    "    def _train_epoch(self, model: torch.nn.Module, compute_loss: Loss, optimizer: Optimizer, dataset: Dataset,\n",
    "                     updates_epoch: int, epoch: int, context_size: int, rel_type_count: int):\n",
    "        self._logger.info(\"Train epoch: %s\" % epoch)\n",
    "\n",
    "        # randomly shuffle data\n",
    "        order = torch.randperm(dataset.document_count)\n",
    "        sampler = self._sampler.create_train_sampler(dataset, self.args.train_batch_size, self.args.max_span_size,\n",
    "                                                     context_size, self.args.neg_entity_count,\n",
    "                                                     self.args.neg_relation_count, order=order, truncate=True)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        iteration = 0\n",
    "        total = dataset.document_count // self.args.train_batch_size\n",
    "        for batch in tqdm(sampler, total=total, desc='Train epoch %s' % epoch):\n",
    "            model.train()\n",
    "\n",
    "            # relation types to one-hot encoding\n",
    "            rel_types_onehot = torch.zeros([batch.rel_types.shape[0], batch.rel_types.shape[1],\n",
    "                                            rel_type_count], dtype=torch.float32).to(self._device)\n",
    "            rel_types_onehot.scatter_(2, batch.rel_types.unsqueeze(2), 1)\n",
    "            rel_types_onehot = rel_types_onehot[:, :, 1:]  # all zeros for 'none' relation\n",
    "\n",
    "            # forward step\n",
    "            entity_logits, rel_logits = model(batch.encodings, batch.ctx_masks, batch.entity_masks,\n",
    "                                              batch.entity_sizes, batch.rels, batch.rel_masks)\n",
    "\n",
    "            # compute loss and optimize parameters\n",
    "            batch_loss = compute_loss.compute(rel_logits, rel_types_onehot, entity_logits,\n",
    "                                              batch.entity_types, batch.rel_sample_masks, batch.entity_sample_masks)\n",
    "\n",
    "            # logging\n",
    "            iteration += 1\n",
    "            global_iteration = epoch * updates_epoch + iteration\n",
    "\n",
    "            if global_iteration % self.args.train_log_iter == 0:\n",
    "                self._log_train(optimizer, batch_loss, epoch, iteration, global_iteration, dataset.label)\n",
    "\n",
    "        return iteration\n",
    "\n",
    "    def _eval(self, model: torch.nn.Module, dataset: Dataset, input_reader: JsonInputReader,\n",
    "              epoch: int = 0, updates_epoch: int = 0, iteration: int = 0):\n",
    "        self._logger.info(\"Evaluate: %s\" % dataset.label)\n",
    "\n",
    "        if isinstance(model, DataParallel):\n",
    "            # currently no multi GPU support during evaluation\n",
    "            model = model.module\n",
    "\n",
    "        # create evaluator\n",
    "        evaluator = Evaluator(dataset, input_reader, self._tokenizer,\n",
    "                              self.args.rel_filter_threshold, self.args.example_count,\n",
    "                              self._examples_path, epoch, dataset.label)\n",
    "\n",
    "        # create batch sampler\n",
    "        sampler = self._sampler.create_eval_sampler(dataset, self.args.eval_batch_size, self.args.max_span_size,\n",
    "                                                    input_reader.context_size, truncate=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            # iterate batches\n",
    "            total = math.ceil(dataset.document_count / self.args.eval_batch_size)\n",
    "            for batch in tqdm(sampler, total=total, desc='Evaluate epoch %s' % epoch):\n",
    "                # move batch to selected device\n",
    "                batch = batch.to(self._device)\n",
    "\n",
    "                # run model (forward pass)\n",
    "                entity_clf, rel_clf, rels = model(batch.encodings, batch.ctx_masks, batch.entity_masks,\n",
    "                                                  batch.entity_sizes, batch.entity_spans, batch.entity_sample_masks,\n",
    "                                                  evaluate=True)\n",
    "\n",
    "                # evaluate batch\n",
    "                evaluator.eval_batch(entity_clf, rel_clf, rels, batch)\n",
    "\n",
    "        global_iteration = epoch * updates_epoch + iteration\n",
    "        ner_eval, rel_eval, rel_nec_eval = evaluator.compute_scores()\n",
    "        self._log_eval(*ner_eval, *rel_eval, *rel_nec_eval,\n",
    "                       epoch, iteration, global_iteration, dataset.label)\n",
    "\n",
    "        if self.args.store_examples:\n",
    "            evaluator.store_examples()\n",
    "\n",
    "    def _get_optimizer_params(self, model):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_params = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "        return optimizer_params\n",
    "\n",
    "    def _log_train(self, optimizer: Optimizer, loss: float, epoch: int,\n",
    "                   iteration: int, global_iteration: int, label: str):\n",
    "        # average loss\n",
    "        avg_loss = loss / self.args.train_batch_size\n",
    "        # get current learning rate\n",
    "        lr = self._get_lr(optimizer)[0]\n",
    "\n",
    "        # log to tensorboard\n",
    "        self._log_tensorboard(label, 'loss', loss, global_iteration)\n",
    "        self._log_tensorboard(label, 'loss_avg', avg_loss, global_iteration)\n",
    "        self._log_tensorboard(label, 'lr', lr, global_iteration)\n",
    "\n",
    "        # log to csv\n",
    "        self._log_csv(label, 'loss', loss, epoch, iteration, global_iteration)\n",
    "        self._log_csv(label, 'loss_avg', avg_loss, epoch, iteration, global_iteration)\n",
    "        self._log_csv(label, 'lr', lr, epoch, iteration, global_iteration)\n",
    "\n",
    "    def _log_eval(self, ner_prec_micro: float, ner_rec_micro: float, ner_f1_micro: float,\n",
    "                  ner_prec_macro: float, ner_rec_macro: float, ner_f1_macro: float,\n",
    "\n",
    "                  rel_prec_micro: float, rel_rec_micro: float, rel_f1_micro: float,\n",
    "                  rel_prec_macro: float, rel_rec_macro: float, rel_f1_macro: float,\n",
    "\n",
    "                  rel_nec_prec_micro: float, rel_nec_rec_micro: float, rel_nec_f1_micro: float,\n",
    "                  rel_nec_prec_macro: float, rel_nec_rec_macro: float, rel_nec_f1_macro: float,\n",
    "                  epoch: int, iteration: int, global_iteration: int, label: str):\n",
    "\n",
    "        # log to tensorboard\n",
    "        self._log_tensorboard(label, 'eval/ner_prec_micro', ner_prec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/ner_recall_micro', ner_rec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/ner_f1_micro', ner_f1_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/ner_prec_macro', ner_prec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/ner_recall_macro', ner_rec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/ner_f1_macro', ner_f1_macro, global_iteration)\n",
    "\n",
    "        self._log_tensorboard(label, 'eval/rel_prec_micro', rel_prec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_recall_micro', rel_rec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_f1_micro', rel_f1_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_prec_macro', rel_prec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_recall_macro', rel_rec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_f1_macro', rel_f1_macro, global_iteration)\n",
    "\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_prec_micro', rel_nec_prec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_recall_micro', rel_nec_rec_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_f1_micro', rel_nec_f1_micro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_prec_macro', rel_nec_prec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_recall_macro', rel_nec_rec_macro, global_iteration)\n",
    "        self._log_tensorboard(label, 'eval/rel_nec_f1_macro', rel_nec_f1_macro, global_iteration)\n",
    "\n",
    "        # log to csv\n",
    "        self._log_csv(label, 'eval', ner_prec_micro, ner_rec_micro, ner_f1_micro,\n",
    "                      ner_prec_macro, ner_rec_macro, ner_f1_macro,\n",
    "\n",
    "                      rel_prec_micro, rel_rec_micro, rel_f1_micro,\n",
    "                      rel_prec_macro, rel_rec_macro, rel_f1_macro,\n",
    "\n",
    "                      rel_nec_prec_micro, rel_nec_rec_micro, rel_nec_f1_micro,\n",
    "                      rel_nec_prec_macro, rel_nec_rec_macro, rel_nec_f1_macro,\n",
    "                      epoch, iteration, global_iteration)\n",
    "\n",
    "    def _log_datasets(self, input_reader):\n",
    "        self._logger.info(\"Relation type count: %s\" % input_reader.relation_type_count)\n",
    "        self._logger.info(\"Entity type count: %s\" % input_reader.entity_type_count)\n",
    "\n",
    "        self._logger.info(\"Entities:\")\n",
    "        for e in input_reader.entity_types.values():\n",
    "            self._logger.info(e.verbose_name + '=' + str(e.index))\n",
    "\n",
    "        self._logger.info(\"Relations:\")\n",
    "        for r in input_reader.relation_types.values():\n",
    "            self._logger.info(r.verbose_name + '=' + str(r.index))\n",
    "\n",
    "        for k, d in input_reader.datasets.items():\n",
    "            self._logger.info('Dataset: %s' % k)\n",
    "            self._logger.info(\"Document count: %s\" % d.document_count)\n",
    "            self._logger.info(\"Relation count: %s\" % d.relation_count)\n",
    "            self._logger.info(\"Entity count: %s\" % d.entity_count)\n",
    "\n",
    "        self._logger.info(\"Context size: %s\" % input_reader.context_size)\n",
    "\n",
    "    def _init_train_logging(self, label):\n",
    "        self._add_dataset_logging(label,\n",
    "                                  data={'lr': ['lr', 'epoch', 'iteration', 'global_iteration'],\n",
    "                                        'loss': ['loss', 'epoch', 'iteration', 'global_iteration'],\n",
    "                                        'loss_avg': ['loss_avg', 'epoch', 'iteration', 'global_iteration']})\n",
    "\n",
    "    def _init_eval_logging(self, label):\n",
    "        self._add_dataset_logging(label,\n",
    "                                  data={'eval': ['ner_prec_micro', 'ner_rec_micro', 'ner_f1_micro',\n",
    "                                                 'ner_prec_macro', 'ner_rec_macro', 'ner_f1_macro',\n",
    "                                                 'rel_prec_micro', 'rel_rec_micro', 'rel_f1_micro',\n",
    "                                                 'rel_prec_macro', 'rel_rec_macro', 'rel_f1_macro',\n",
    "                                                 'rel_nec_prec_micro', 'rel_nec_rec_micro', 'rel_nec_f1_micro',\n",
    "                                                 'rel_nec_prec_macro', 'rel_nec_rec_macro', 'rel_nec_f1_macro',\n",
    "                                                 'epoch', 'iteration', 'global_iteration']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
